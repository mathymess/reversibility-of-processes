{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b98d204",
   "metadata": {},
   "source": [
    "# Mutual information estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09e00fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code imports\n",
    "from generate_time_series import (load_two_body_problem_time_series,\n",
    "                                  load_belousov_zhabotinsky_time_series,\n",
    "                                  load_lorenz_attractor_time_series)\n",
    "\n",
    "from datasets import (chop_time_series_into_chunks,\n",
    "                      split_chunks_into_windows_and_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa5d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard code imports\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import numpy.typing\n",
    "NDArray = numpy.typing.NDArray[np.floating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3446fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def time_series_2_windows_and_targets(time_series: NDArray,\n",
    "                                      window_len: int = 10,\n",
    "                                      target_len: int = 1,\n",
    "                                      reverse: bool = False) -> Tuple[NDArray, NDArray]:\n",
    "    chunks = chop_time_series_into_chunks(time_series,\n",
    "                                          chunk_len=window_len+target_len,\n",
    "                                          reverse=reverse,\n",
    "                                          take_each_nth_chunk=3)\n",
    "    windows, targets = split_chunks_into_windows_and_targets(chunks, target_len=target_len)\n",
    "    return windows, targets\n",
    "\n",
    "\n",
    "def flatten_last_dim(array: NDArray) -> NDArray:\n",
    "    assert array.ndim >= 2\n",
    "    return array.reshape((*array.shape[:-2], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b999ef",
   "metadata": {},
   "source": [
    "## `sklearn.feature_selection.mutual_info_regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c4f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This function only works with discrete inputs (handy for categorization/clusterization).\n",
    "# # It is unusable for the float (continuous) vectors we are dealing with here.\n",
    "# from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "702a0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://www.blog.trainindata.com/mutual-information-with-python/\n",
    "from sklearn.feature_selection import mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "14761608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutual_info_for_dataset(ts: NDArray, dim: int = 0) -> Tuple[NDArray, NDArray]:\n",
    "    assert 0 <= dim < ts.shape[1]\n",
    "\n",
    "    forward_windows, forward_targets = time_series_2_windows_and_targets(ts)\n",
    "    backward_windows, backward_targets = time_series_2_windows_and_targets(ts, reverse=True)\n",
    "\n",
    "    # Each window or target is two-dimensional. I extract just one dimension\n",
    "    backward_windows = backward_windows[:, :, dim]\n",
    "    forward_windows = forward_windows[:, :, dim]\n",
    "    # ... and assume target_len=1, so take the 0-th point in target.\n",
    "    forward_targets = forward_targets[:, 0, dim]\n",
    "    backward_targets = backward_targets[:, 0, dim]\n",
    "    # Note: `mutual_info_regression` only accepts 1-dimensional y's.\n",
    "    # So I'm forced to pick only one dimension from targets, although I could\n",
    "    # flatten the windows instead of extracting one dimension from it.\n",
    "\n",
    "    return (mutual_info_regression(forward_windows, forward_targets),\n",
    "            mutual_info_regression(backward_windows, backward_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "320978c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mutual_info(ts: NDArray, comment: str) -> None:\n",
    "    forward, backward = calculate_mutual_info_for_dataset(ts)\n",
    "    print(comment, \"forward\", forward)\n",
    "    print(comment, \"backward\", backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5752905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kepler forward [4.1544507  4.1679777  4.19014217 4.23306892 4.40380346 4.52204556\n",
      " 4.6513439  4.83707335 5.07009635 5.38225062]\n",
      "kepler backward [4.1544507  4.16829816 4.19438907 4.23299843 4.40411548 4.52240252\n",
      " 4.65179145 4.83874348 5.06217402 5.38334711]\n",
      "\n",
      "belousov_zhabotinsky forward [5.10297078 5.11591333 5.12894595 5.15271997 5.2606767  5.40564618\n",
      " 5.4406048  5.48620959 5.54904934 5.63826422]\n",
      "belousov_zhabotinsky backward [5.10354369 5.11591333 5.12937203 5.1472664  5.23061426 5.39968754\n",
      " 5.42965822 5.4778498  5.53905855 5.6281999 ]\n",
      "\n",
      "lorenz forward [1.10491599 1.18068127 1.28136143 1.39081549 1.52221169 1.68715116\n",
      " 1.89150051 2.17183271 2.57736067 3.26623382]\n",
      "lorenz backward [1.10105144 1.18418257 1.28136143 1.38803675 1.51959223 1.68800725\n",
      " 1.90041139 2.17751784 2.57858673 3.25964205]\n"
     ]
    }
   ],
   "source": [
    "print_mutual_info(load_two_body_problem_time_series(), \"kepler\")\n",
    "print()\n",
    "print_mutual_info(load_belousov_zhabotinsky_time_series(), \"belousov_zhabotinsky\")\n",
    "print()\n",
    "print_mutual_info(load_lorenz_attractor_time_series(), \"lorenz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d40ce",
   "metadata": {},
   "source": [
    "The numbers about are the same, within reasonable accuracy, for `forward` and `backward`.\n",
    "This is not what we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0ccc1",
   "metadata": {},
   "source": [
    "## gregversteeg/NPEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9424456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NPEET'...\n",
      "remote: Enumerating objects: 129, done.\u001b[K\n",
      "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
      "remote: Total 129 (delta 21), reused 35 (delta 19), pack-reused 87\u001b[K\n",
      "Receiving objects: 100% (129/129), 317.14 KiB | 868.00 KiB/s, done.\n",
      "Resolving deltas: 100% (55/55), done.\n"
     ]
    }
   ],
   "source": [
    "# Install the module from GitHub\n",
    "!git clone https://github.com/gregversteeg/NPEET.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d13acdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The module's suggested installation method doesn't work,\n",
    "# so we just find the right source file in the directory tree.\n",
    "from NPEET.npeet import entropy_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6fd0a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mutual_info_for_dataset(ts: NDArray) -> Tuple[NDArray, NDArray]:\n",
    "    forward_windows, forward_targets = time_series_2_windows_and_targets(ts)\n",
    "    backward_windows, backward_targets = time_series_2_windows_and_targets(ts, reverse=True)\n",
    "\n",
    "    # Each window or target is two-dimensional, so I flatten them.\n",
    "    backward_windows = flatten_last_dim(backward_windows)\n",
    "    forward_windows = flatten_last_dim(forward_windows)\n",
    "    backward_targets = flatten_last_dim(backward_targets)\n",
    "    forward_targets = flatten_last_dim(forward_targets)\n",
    "\n",
    "    return (entropy_estimators.mi(forward_windows, forward_targets),\n",
    "            entropy_estimators.mi(backward_windows, backward_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee018779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.074050021439163, 8.047722644831461)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mutual_info_for_dataset(load_two_body_problem_time_series())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e79646e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.368706642394997, 9.357729704269742)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mutual_info_for_dataset(load_lorenz_attractor_time_series())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1eb0d9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.951617233018499, 8.087579162293846)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_mutual_info_for_dataset(load_belousov_zhabotinsky_time_series())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
