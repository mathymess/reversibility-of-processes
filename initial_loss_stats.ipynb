{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f169e3cc",
   "metadata": {},
   "source": [
    "# Initial loss stats\n",
    "\n",
    "I noticed a weird trend in the last tensorboards: the initial loss of the model is almost always greater on the reversed (i.e. labeled `backward`) dataset than in non-reversed one (labeled `forward`).\n",
    "This looks suspicious, because for randomly initialized weights, the untrained model's loss should be equally likely greater for `forward` than for `backward` and for vice versa.\n",
    "\n",
    "Most likely explanation is, the first point on my tensorboard learning curve plots corresponds to the loss _after the first epoch_, i.e. after some training has already been done.\n",
    "Maybe I should call tensorboard callback just before the training loop to add the initial point.\n",
    "\n",
    "Anyway, I explore this trend more rigorously in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c53d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code imports\n",
    "from models import ThreeFullyConnectedLayers\n",
    "\n",
    "from generate_time_series import (load_two_body_problem_time_series,\n",
    "                                  load_lorenz_attractor_time_series,\n",
    "                                  load_belousov_zhabotinsky_time_series)\n",
    "\n",
    "from datasets import (prepare_time_series_for_learning,\n",
    "                      time_series_to_dataset,\n",
    "                      AllDataHolder)\n",
    "\n",
    "from train_test_utils import get_mean_loss_on_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34084543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard modules import\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c651b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataholders\n",
    "def load_two_body_problem_dataholder(window_len: int,\n",
    "                                     target_len: int) -> AllDataHolder:\n",
    "    twb = load_two_body_problem_time_series()\n",
    "    dh = prepare_time_series_for_learning(train_ts=twb,\n",
    "                                          test_ts=twb.copy(),\n",
    "                                          window_len=window_len,\n",
    "                                          target_len=target_len,\n",
    "                                          take_each_nth_chunk=1)\n",
    "    return dh\n",
    "\n",
    "\n",
    "def load_lorenz_attractor_dataholder(window_len: int,\n",
    "                                     target_len: int) -> AllDataHolder:\n",
    "    lrz = load_lorenz_attractor_time_series()\n",
    "    dh = prepare_time_series_for_learning(train_ts=lrz,\n",
    "                                          test_ts=lrz.copy(),\n",
    "                                          window_len=window_len,\n",
    "                                          target_len=target_len,\n",
    "                                          take_each_nth_chunk=1)\n",
    "    return dh\n",
    "\n",
    "\n",
    "def load_belousov_zhabotinsky_dataholder(window_len: int,\n",
    "                                         target_len: int) -> AllDataHolder:\n",
    "    bzh = load_belousov_zhabotinsky_time_series()\n",
    "    dh = prepare_time_series_for_learning(train_ts=bzh,\n",
    "                                          test_ts=bzh.copy(),\n",
    "                                          window_len=window_len,\n",
    "                                          target_len=target_len,\n",
    "                                          take_each_nth_chunk=1)\n",
    "    return dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1c461bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_difference(model: ThreeFullyConnectedLayers,\n",
    "                        dh: AllDataHolder) -> float:\n",
    "    loss_forw = get_mean_loss_on_test_dataset(model, dh.forward.test_dataset)\n",
    "    loss_back = get_mean_loss_on_test_dataset(model, dh.backward.test_dataset)\n",
    "    return loss_back - loss_forw\n",
    "\n",
    "def get_loss_difference_kepler(window_len: int = 20,\n",
    "                               target_len: int = 1,\n",
    "                               size: int = 7) -> float:\n",
    "    dh = load_two_body_problem_dataholder(window_len=window_len,\n",
    "                                          target_len=target_len)\n",
    "    m = ThreeFullyConnectedLayers(window_len=window_len, target_len=target_len,\n",
    "                                  hidden_layer1_size=size, hidden_layer2_size=size,\n",
    "                                  datapoint_size=2)\n",
    "    return get_loss_difference(m, dh)\n",
    "\n",
    "def get_loss_difference_lorenz(window_len: int = 20,\n",
    "                               target_len: int = 1,\n",
    "                               size: int = 10) -> float:\n",
    "    dh = load_lorenz_attractor_dataholder(window_len=window_len,\n",
    "                                          target_len=target_len)\n",
    "    m = ThreeFullyConnectedLayers(window_len=window_len, target_len=target_len,\n",
    "                                  hidden_layer1_size=size, hidden_layer2_size=size,\n",
    "                                  datapoint_size=3)\n",
    "    return get_loss_difference(m, dh)\n",
    "\n",
    "def get_loss_difference_belousov_zhabotinsky(window_len: int = 20,\n",
    "                                             target_len: int = 1,\n",
    "                                             size: int = 10) -> float:\n",
    "    dh = load_belousov_zhabotinsky_dataholder(window_len=window_len,\n",
    "                                              target_len=target_len)\n",
    "    m = ThreeFullyConnectedLayers(window_len=window_len, target_len=target_len,\n",
    "                                  hidden_layer1_size=size, hidden_layer2_size=size,\n",
    "                                  datapoint_size=3)\n",
    "    return get_loss_difference(m, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "345496e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 3.31 ms, total: 526 ms\n",
      "Wall time: 487 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.000408440898611806"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time get_loss_difference_kepler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c5e91c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCalculator:\n",
    "    def __init__(self,\n",
    "                 system: str,\n",
    "                 window_len: int = 20,\n",
    "                 target_len: int = 1,\n",
    "                 size: int = 7) -> None:\n",
    "        self.window_len = window_len\n",
    "        self.target_len = target_len\n",
    "        self.size = size\n",
    "        \n",
    "        if system == \"kepler\":\n",
    "            loader_func = load_two_body_problem_dataholder\n",
    "            self.datapoint_size = 2\n",
    "        elif system == \"lorenz\":\n",
    "            loader_func = load_lorenz_attractor_dataholder\n",
    "            self.datapoint_size = 3\n",
    "        elif system == \"belousov-zhabotinsky\":\n",
    "            loader_func = load_belousov_zhabotinsky_dataholder\n",
    "            self.datapoint_size = 3\n",
    "        else:\n",
    "            raise ValueError(f\"system={system}, expected one of 'kepler', 'lorenz', 'belousov-zhabotinsky'\")\n",
    "        \n",
    "        self.dh = loader_func(window_len=window_len, target_len=target_len)\n",
    "        \n",
    "    def __call__(self):\n",
    "        m = ThreeFullyConnectedLayers(window_len=self.window_len,\n",
    "                                      target_len=self.target_len,\n",
    "                                      hidden_layer1_size=self.size,\n",
    "                                      hidden_layer2_size=self.size,\n",
    "                                      datapoint_size=self.datapoint_size)\n",
    "        return get_loss_difference(m, self.dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "959b2ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = LossCalculator(system=\"kepler\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
